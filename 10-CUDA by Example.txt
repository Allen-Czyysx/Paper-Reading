1. 06年提出cuda结构，针对通用计算，不再仅限于用gpu来做图像处理

2. device和host之间不能互相间接引用对方内存的指针，须调用cuda函数

3. 有时需要自己在代码里根据property选择gpu，cuda runtime不一定会选择最好的

4. block内线程可通过shared memory共享内存，一般16KB, 比global memory快

5. 内存IO是瓶颈，多线程同时读取相同内存数据时使用constant memory，线程读取临近内存时使用texture memory

6. 线程不安全，可用原子操作函数解决，但是会带来性能问题，应尽量改善算法（如使用shared memory）减少竞争

7. 从host复制数据到device上时，首先会将数据从可换页的内存区域复制到固定页上，再让gpu从固定页上获取数据。使用cudaHostAlloc()可直接申请固定页的内存空间

8. 使用stream提高memcpy和kernel操作的并发度

9. 对于integrated gpu可使用page-locked host memory提高速度。对于单次读写操作的数据，也可以用来减少内存带宽的竞争

10. zero-copy memory的内存复制不由用户控制，而是在代码需要的时候由cuda runtime进行复制，可用于对同一处内存仅做一次读/写的情况

11. unified memory把内存复制的操作完全交给系统，对用户透明，省去了显式的内存复制，极大缩减了代码，且性能影响不大

12. 使用多个gpu时，一个gpu一个线程。多线程若想使用zero-copy memory，须加上portable，不能在子线程中申请zero-copy memory
