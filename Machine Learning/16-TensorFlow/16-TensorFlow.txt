目标: TensorFlow, 机器学习框架, 提供算法描述接口和算法实现. 可应用于不同系统 (从移动设备到大型分布式系统).

与DistBelief (google一代机器学习框架) 相比:
	1) 编程模型更灵活.
	2) 性能提升极大.
	3) 支持训练更多的模型和部署在更多样的硬件平台上.

编程模型:
	1) 用户代码->有向图: 节点=算子; 普通边=张量数据; 特殊边=控制依赖关系 (如用户用来指定算子B必须在算子A完成后执行, 从而控制占用的内存峰值).
	2) Variable: 一种操作, 在程序的生命周期内维持某个可变的张量. 常用于存储模型参数, 在运行中不断更新.

实现:
	1) 架构: 一个master, 多个worker, 每个woker负责一个或多个device, 每个device负责一个或多个operation.
	2) Node placement: 从有向图的起点开始, 对每个节点, 从可用device集中选出最快的 (选择依据: 代价模型, 静态估计或历史记录统计; 数据传输时间).
	3) Cross-device communication: 每个cross-device edge中插入一对send, receive节点, 专门负责数据传输, 从而不需要master管理 (去中心化).
	4) 容错: 通过send, receive对报错和心跳发现错误, 从checkpoint开始重新执行. checkpoint由variable节点进行持久化 (如存放在分布式文件系统).

优化:
	1) receive节点的过早启动: 分析关键路径, 得到需要启动receive节点的时间 (添加控制边以延后启动时间).
	2) 有损压缩: 一些算法容忍不精确的数据, 通过有损压缩降低网络IO.

------------------------

内容: Dataflow模型

设计原则:
	1) 初始算子: 提供矩阵乘法, 卷积等数学算子给用户, 便于用户使用和系统计算模型微分 (?).
	2) 延迟执行: 在整个程序可用 (完成优化...) 后才开始执行.

执行模型:
	1) Tensor: 将所有数据视为tensor (元素为int, float或string). 底层管理中, 所有tensor是稠密的 (稀疏tensor转变成稠密的结构).
	2) Stateful operation: 可变状态, 分为2类, 变量和队列.
	3) 部分并发执行: 子图之间通过变量和队列 (瓶颈?) 交互, 子图内并发执行 (通常异步执行, 弱一致性).
	4) 动态控制流: 支持在图中添加条件分支, 循环.
